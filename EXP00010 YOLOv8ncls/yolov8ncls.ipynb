{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1994091,"sourceType":"datasetVersion","datasetId":899128},{"sourceId":8202172,"sourceType":"datasetVersion","datasetId":4859203}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom pathlib import Path\nimport yaml\nimport cv2 as cv\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-05T03:38:03.481340Z","iopub.execute_input":"2024-06-05T03:38:03.482061Z","iopub.status.idle":"2024-06-05T03:38:04.296973Z","shell.execute_reply.started":"2024-06-05T03:38:03.482013Z","shell.execute_reply":"2024-06-05T03:38:04.296083Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def prev_im(image, string=\"\"):\n    \"\"\"\n    Display an image in a window with OpenCV.\n\n    Parameters:\n    ---\n    image : numpy.ndarray\n        The image to be displayed, expected to be in the format readable by OpenCV (usually uint8, with dimensions [height, width, channels]).\n    string : str, optional\n        The title of the window in which the image will be displayed. Default is an empty string.\n\n    Returns:\n    ---\n    None\n    \"\"\"\n    cv.imshow(string, image)  # Display the image in a window with the title provided in 'string'.\n    cv.waitKey(0)            # Wait indefinitely until a key is pressed.\n    cv.destroyAllWindows()   # Close all OpenCV windows.","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:38:04.298518Z","iopub.execute_input":"2024-06-05T03:38:04.298862Z","iopub.status.idle":"2024-06-05T03:38:04.304588Z","shell.execute_reply.started":"2024-06-05T03:38:04.298836Z","shell.execute_reply":"2024-06-05T03:38:04.303536Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Image Processing - Grayscale Conversion\ndef gen_gray_img(map_data: np.ndarray, debug=False):\n    \"\"\"\n    Generate a gray-scale image from wafer data.\n\n    Parameters:\n    ---\n    map_data : numpy.ndarray\n        Wafer data map with pixel values of (0, 1, 2); 0=non-wafer, 1=good wafer, 2=bad wafer.\n    debug : bool, optional\n        If True, performs checks and logs issues instead of raising exceptions.\n\n    Returns:\n    ---\n    numpy.ndarray\n        Gray-scale image with pixel values (0, 128, 255).\n    \"\"\"\n    expected_values = {0, 1, 2}\n    unique_values = np.unique(map_data)\n    \n    if not expected_values.issuperset(unique_values):\n        if debug:\n            print(f\"Unexpected values found in map_data: {unique_values}\")\n            return None\n        else:\n            raise ValueError(f\"Map values do not match expected values (0, 1, 2)\")\n\n    gray = np.copy(map_data)\n    gray[gray == 1] += 127\n    gray[gray == 2] += 253  # direct assignment to max value for clarity\n\n    return gray.astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:38:04.305776Z","iopub.execute_input":"2024-06-05T03:38:04.306069Z","iopub.status.idle":"2024-06-05T03:38:04.315529Z","shell.execute_reply.started":"2024-06-05T03:38:04.306046Z","shell.execute_reply":"2024-06-05T03:38:04.314714Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Image Processing - Colour Encoding\ndef gray_to_color(gray_map:np.ndarray,\n                  bad_clr:tuple=(255,255,0),\n                  good_clr:tuple=(25,102,255)):\n    \"\"\"\n    Usage\n    ---\n    Convert gray-scale image to color image using `good_clr` and `bad_clr` BGR colors\n\n    Parameters\n    ---\n    gray_map : ``numpy.ndarray``\n    bad_clr : ``tuple`` optional,\n        BGR color values to use for 'bad' pixels, `default=(255,255,0)` \"Pumpkin\"\n    good_clr : ``tuple`` optional,\n        BGR color values to use for 'good' pixels, `default=(25,102,255)` \"Aqua\"\n\n    Returns\n    ---\n    BGR color image of wafer map, using `good_clr` and `bad_clr` pixel values\n\n    \"\"\"\n    assert all([n in np.unique(gray_map) for n in [0,128,255]]), f\"Gray scale values do not match expected values (0, 128, 255)\"\n\n    color_map = cv.cvtColor(np.copy(gray_map),cv.COLOR_GRAY2BGR) # B, G, R\n    \n    for d in range(color_map.shape[-1]):\n            color_map[:,:,d][color_map[:,:,d] == 255] = bad_clr[d]\n            color_map[:,:,d][color_map[:,:,d] == 128] = good_clr[d]\n    \n    return color_map","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:38:04.318213Z","iopub.execute_input":"2024-06-05T03:38:04.319043Z","iopub.status.idle":"2024-06-05T03:38:04.327866Z","shell.execute_reply.started":"2024-06-05T03:38:04.319010Z","shell.execute_reply":"2024-06-05T03:38:04.327065Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Data Loading\nimport pandas as pd\ndata = np.load(\"/kaggle/input/mixedtype-wafer-defect-datasets/Wafer_Map_Datasets.npz\")","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:38:04.328788Z","iopub.execute_input":"2024-06-05T03:38:04.329034Z","iopub.status.idle":"2024-06-05T03:38:04.708819Z","shell.execute_reply.started":"2024-06-05T03:38:04.329006Z","shell.execute_reply":"2024-06-05T03:38:04.707983Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Seperate wafer map data and labels\nimgs = data['arr_0'] # shape (38015, 52, 52)\nlbls = data['arr_1'] # shape (38015, 8)\n\n# Get unique labels\nunique_lbls = np.unique(lbls,axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:38:04.709970Z","iopub.execute_input":"2024-06-05T03:38:04.710386Z","iopub.status.idle":"2024-06-05T03:38:08.734485Z","shell.execute_reply.started":"2024-06-05T03:38:04.710359Z","shell.execute_reply":"2024-06-05T03:38:08.733645Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Convert each label row to a tuple for it to be hashable\nlabel_tuples = [tuple(label) for label in lbls]\n\n# Use a dictionary to count occurrences of each unique label\nlabel_count = {}\nfor label in label_tuples:\n    if label in label_count:\n        label_count[label] += 1\n    else:\n        label_count[label] = 1\n\n# Display the counts\nfor label, count in label_count.items():\n    print(f\"Label {label}: {count} images\")","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:38:08.735626Z","iopub.execute_input":"2024-06-05T03:38:08.735940Z","iopub.status.idle":"2024-06-05T03:38:08.951351Z","shell.execute_reply.started":"2024-06-05T03:38:08.735915Z","shell.execute_reply":"2024-06-05T03:38:08.950489Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Label (1, 0, 1, 0, 0, 0, 1, 0): 2000 images\nLabel (1, 0, 1, 0, 0, 0, 0, 0): 1000 images\nLabel (1, 0, 0, 1, 0, 0, 1, 0): 1000 images\nLabel (1, 0, 0, 1, 0, 0, 0, 0): 1000 images\nLabel (1, 0, 1, 0, 1, 0, 1, 0): 1000 images\nLabel (1, 0, 1, 0, 1, 0, 0, 0): 1000 images\nLabel (1, 0, 0, 1, 1, 0, 1, 0): 1000 images\nLabel (1, 0, 0, 1, 1, 0, 0, 0): 1000 images\nLabel (1, 0, 0, 0, 1, 0, 1, 0): 1000 images\nLabel (1, 0, 0, 0, 1, 0, 0, 0): 1000 images\nLabel (1, 0, 0, 0, 0, 0, 1, 0): 1000 images\nLabel (1, 0, 0, 0, 0, 0, 0, 0): 1000 images\nLabel (0, 1, 1, 0, 0, 0, 1, 0): 1000 images\nLabel (0, 1, 1, 0, 0, 0, 0, 0): 1000 images\nLabel (0, 1, 0, 1, 0, 0, 1, 0): 1000 images\nLabel (0, 1, 0, 1, 0, 0, 0, 0): 1000 images\nLabel (0, 1, 1, 0, 1, 0, 1, 0): 1000 images\nLabel (0, 1, 1, 0, 1, 0, 0, 0): 1000 images\nLabel (0, 1, 0, 1, 1, 0, 1, 0): 1000 images\nLabel (0, 1, 0, 1, 1, 0, 0, 0): 1000 images\nLabel (0, 1, 0, 0, 1, 0, 1, 0): 1000 images\nLabel (0, 1, 0, 0, 1, 0, 0, 0): 1000 images\nLabel (0, 1, 0, 0, 0, 0, 1, 0): 1000 images\nLabel (0, 1, 0, 0, 0, 0, 0, 0): 1000 images\nLabel (0, 0, 1, 0, 0, 0, 0, 0): 1000 images\nLabel (0, 0, 0, 1, 0, 0, 0, 0): 1000 images\nLabel (0, 0, 1, 0, 1, 0, 1, 0): 1000 images\nLabel (0, 0, 1, 0, 1, 0, 0, 0): 1000 images\nLabel (0, 0, 0, 1, 1, 0, 1, 0): 1000 images\nLabel (0, 0, 0, 1, 1, 0, 0, 0): 1000 images\nLabel (0, 0, 0, 0, 1, 0, 1, 0): 1000 images\nLabel (0, 0, 0, 0, 1, 0, 0, 0): 1000 images\nLabel (0, 0, 0, 0, 0, 0, 0, 1): 866 images\nLabel (0, 0, 0, 0, 0, 0, 0, 0): 1000 images\nLabel (0, 0, 0, 0, 0, 1, 0, 0): 149 images\nLabel (0, 0, 1, 0, 0, 0, 1, 0): 1000 images\nLabel (0, 0, 0, 1, 0, 0, 1, 0): 1000 images\nLabel (0, 0, 0, 0, 0, 0, 1, 0): 1000 images\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load encoding file and create string labels\n# YAML file provides a structured way to map arrays of numeric labels to human-readable strings, which describe various types of wafer defects.\nencodes_path = \"/kaggle/input/encodings-yaml/encodings.yaml\"\nwith open(encodes_path, 'r') as enc:\n    encd = yaml.safe_load(enc)\n\nstr_lbls = [str(l) for l in lbls]","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:38:08.952608Z","iopub.execute_input":"2024-06-05T03:38:08.953080Z","iopub.status.idle":"2024-06-05T03:38:11.619489Z","shell.execute_reply.started":"2024-06-05T03:38:08.953040Z","shell.execute_reply":"2024-06-05T03:38:11.618390Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Show the number of unique pixel values in the uncleaned data\nunique_pixels = set()  # To store all unique pixel values across all images\nbad_wafers = []        # To store images that are considered bad based on pixel values\n\n# Analyze each wafer image\nfor img in imgs:\n    vals = np.unique(img).tolist()  # Get unique pixel values in the current image\n    unique_pixels.update(vals)      # Update the set of unique pixel values\n\n    # Check for unexpected pixel values\n    if len(vals) > 3:\n        bad_wafers.append(img)      # Append to bad wafers if unexpected values are found\n\n# Display the results\nprint(f\"Unique pixel values before cleaning: {unique_pixels}\")\nprint(f\"Number of bad wafers: {len(bad_wafers)}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:38:11.621197Z","iopub.execute_input":"2024-06-05T03:38:11.621591Z","iopub.status.idle":"2024-06-05T03:38:13.432183Z","shell.execute_reply.started":"2024-06-05T03:38:11.621555Z","shell.execute_reply":"2024-06-05T03:38:13.431164Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Unique pixel values before cleaning: {0, 1, 2, 3}\nNumber of bad wafers: 105\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fix imgs with more than 3 pixel values\n# should ONLY have 0,1,2 for values\n# see https://github.com/Junliangwangdhu/WaferMap/issues/2\nfor im in imgs:\n    val = np.unique(im)\n    if len(val) > 3:\n        im[im == 3] = 2","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:38:13.436732Z","iopub.execute_input":"2024-06-05T03:38:13.437102Z","iopub.status.idle":"2024-06-05T03:38:15.168581Z","shell.execute_reply.started":"2024-06-05T03:38:13.437074Z","shell.execute_reply":"2024-06-05T03:38:15.167398Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Train-Test split\n# y is generated by mapping the labels (lbls) to their corresponding encoded keys using a dictionary (encd).\nX, y = imgs, [list(encd.keys())[list(encd.values()).index(k.tolist())] for k in lbls] \n\n# Split data into test and temp sets\nX_train_temp, X_test, y_train_temp, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n\n# Further split the temp set into train and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_train_temp, y_train_temp, test_size=0.2, random_state=10)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:38:15.169984Z","iopub.execute_input":"2024-06-05T03:38:15.170307Z","iopub.status.idle":"2024-06-05T03:38:15.552304Z","shell.execute_reply.started":"2024-06-05T03:38:15.170278Z","shell.execute_reply":"2024-06-05T03:38:15.551200Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Review counts to analyze the distribution of labels across your training, validation, and test sets after the data split.\ntrain_lbl_counts = {k:v for k,v in zip(*np.unique(y_train,return_counts=True))}\nval_lbl_counts = {k:v for k,v in zip(*np.unique(y_val,return_counts=True))}\ntest_lbl_counts = {k:v for k,v in zip(*np.unique(y_test,return_counts=True))}","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:38:15.553814Z","iopub.execute_input":"2024-06-05T03:38:15.554222Z","iopub.status.idle":"2024-06-05T03:38:15.582427Z","shell.execute_reply.started":"2024-06-05T03:38:15.554185Z","shell.execute_reply":"2024-06-05T03:38:15.581517Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Define directory paths\ntrain_dir = '/kaggle/working/data/train'\nval_dir = '/kaggle/working/data/val'\ntest_dir = '/kaggle/working/data/test'\n\n# Create directories if they don't exist\nos.makedirs(train_dir, exist_ok=True)\nos.makedirs(val_dir, exist_ok=True)\nos.makedirs(test_dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:38:15.583486Z","iopub.execute_input":"2024-06-05T03:38:15.583770Z","iopub.status.idle":"2024-06-05T03:38:15.589700Z","shell.execute_reply.started":"2024-06-05T03:38:15.583746Z","shell.execute_reply":"2024-06-05T03:38:15.588721Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Train\n# Directory setup for each class, image processing, image resizing, saving the processed image\nfor ct, t in enumerate(X_train):\n    cls_dir = f\"{train_dir}/{y_train[ct]}\"\n    if not Path(cls_dir).exists():\n        _ = Path.mkdir(Path(cls_dir))\n    else:\n        pass\n    filename = f\"{cls_dir}/{ct}.png\"\n    color = gray_to_color(gen_gray_img(t))\n    stride_szd = cv.resize(np.copy(color),(64,64),interpolation=cv.INTER_CUBIC)\n    _ = cv.imwrite(filename,stride_szd)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:38:15.590891Z","iopub.execute_input":"2024-06-05T03:38:15.591171Z","iopub.status.idle":"2024-06-05T03:38:39.599945Z","shell.execute_reply.started":"2024-06-05T03:38:15.591147Z","shell.execute_reply":"2024-06-05T03:38:39.599114Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Validate\n# Directory setup for each class, image processing, image resizing, saving the processed image\nfor cval,val in enumerate(X_val):\n    cls_dir = f\"{val_dir}/{y_val[cval]}\"\n    if not Path(cls_dir).exists():\n        _ = Path.mkdir(Path(cls_dir))\n    else:\n        pass\n    filename = f\"{cls_dir}/{cval}.png\"\n    color = gray_to_color(gen_gray_img(val))\n    stride_szd = cv.resize(np.copy(color),(64,64),interpolation=cv.INTER_CUBIC)\n    _ = cv.imwrite(filename,stride_szd)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:38:39.601064Z","iopub.execute_input":"2024-06-05T03:38:39.601359Z","iopub.status.idle":"2024-06-05T03:38:45.562607Z","shell.execute_reply.started":"2024-06-05T03:38:39.601334Z","shell.execute_reply":"2024-06-05T03:38:45.561709Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Test\n# Directory setup for each class, image processing, image resizing, saving the processed image\nfor ctest,test in enumerate(X_test):\n    cls_dir = f\"{test_dir}/{y_test[ctest]}\"\n    if not Path(cls_dir).exists():\n        _ = Path.mkdir(Path(cls_dir))\n    else:\n        pass\n    filename = f\"{cls_dir}/{ctest}.png\"\n    color = gray_to_color(gen_gray_img(test))\n    stride_szd = cv.resize(np.copy(color),(64,64),interpolation=cv.INTER_CUBIC)\n    _ = cv.imwrite(filename,stride_szd)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:38:45.563820Z","iopub.execute_input":"2024-06-05T03:38:45.564211Z","iopub.status.idle":"2024-06-05T03:38:58.410620Z","shell.execute_reply.started":"2024-06-05T03:38:45.564177Z","shell.execute_reply":"2024-06-05T03:38:58.409345Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Generate color images for ALL wafer maps and save images to labeled directory\nfor k, v in encd.items():\n    # Define the directory path\n    directory_path = f'./wafers/{k}'\n    \n    # Check if the parent directory exists, if not create it\n    if not os.path.exists(directory_path):\n        os.makedirs(directory_path)\n    \n    # Get indices of matching groups\n    values, *_ = np.where(np.array(str_lbls) == str(v).replace(',', ''))\n\n    for idx in values:\n        # Create grayscale image\n        gray = gen_gray_img(imgs[idx])\n\n        # Convert to color\n        color = gray_to_color(gray)\n\n        # Resize for YOLO model, (64 x 64); multiple of model stride 32\n        stride_szd = cv.resize(np.copy(color), (64, 64), interpolation=cv.INTER_CUBIC)\n        _ = cv.imwrite(f'./wafers/{k}/' + str(idx) + '.png', stride_szd)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:38:58.412022Z","iopub.execute_input":"2024-06-05T03:38:58.412409Z","iopub.status.idle":"2024-06-05T03:39:40.641918Z","shell.execute_reply.started":"2024-06-05T03:38:58.412373Z","shell.execute_reply":"2024-06-05T03:39:40.641022Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"!pip install ultralytics\nfrom ultralytics import YOLO\nfrom pathlib import Path\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:39:40.643200Z","iopub.execute_input":"2024-06-05T03:39:40.643574Z","iopub.status.idle":"2024-06-05T03:39:59.883281Z","shell.execute_reply.started":"2024-06-05T03:39:40.643539Z","shell.execute_reply":"2024-06-05T03:39:59.882187Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.2.28-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.82)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.4)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.2)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.16.2)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.1)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=0.2.5 (from ultralytics)\n  Downloading ultralytics_thop-0.2.7-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.2.28-py3-none-any.whl (779 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-0.2.7-py3-none-any.whl (25 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.2.28 ultralytics-thop-0.2.7\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load a model\nmodel = YOLO('yolov8n-cls.yaml')  \ndata_dir = Path(\"/kaggle/working/data\")\n\nmodel.to('cuda') if model.device.type == 'cpu' else None #moves the model to a CUDA-enabled GPU","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:39:59.884684Z","iopub.execute_input":"2024-06-05T03:39:59.885172Z","iopub.status.idle":"2024-06-05T03:40:00.327246Z","shell.execute_reply.started":"2024-06-05T03:39:59.885130Z","shell.execute_reply":"2024-06-05T03:40:00.326411Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"YOLOv8n-cls summary: 99 layers, 2719288 parameters, 2719288 gradients, 4.4 GFLOPs\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"YOLO(\n  (model): ClassificationModel(\n    (model): Sequential(\n      (0): Conv(\n        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n      (1): Conv(\n        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n      (2): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (cv2): Conv(\n          (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act): SiLU()\n            )\n            (cv2): Conv(\n              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act): SiLU()\n            )\n          )\n        )\n      )\n      (3): Conv(\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n      (4): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (cv2): Conv(\n          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (m): ModuleList(\n          (0-1): 2 x Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act): SiLU()\n            )\n            (cv2): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act): SiLU()\n            )\n          )\n        )\n      )\n      (5): Conv(\n        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n      (6): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (cv2): Conv(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (m): ModuleList(\n          (0-1): 2 x Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act): SiLU()\n            )\n            (cv2): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act): SiLU()\n            )\n          )\n        )\n      )\n      (7): Conv(\n        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n      (8): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (cv2): Conv(\n          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act): SiLU()\n            )\n            (cv2): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act): SiLU()\n            )\n          )\n        )\n      )\n      (9): Classify(\n        (conv): Conv(\n          (conv): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (pool): AdaptiveAvgPool2d(output_size=1)\n        (drop): Dropout(p=0.0, inplace=True)\n        (linear): Linear(in_features=1280, out_features=1000, bias=True)\n      )\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"print(os.getcwd())","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:40:00.328669Z","iopub.execute_input":"2024-06-05T03:40:00.329091Z","iopub.status.idle":"2024-06-05T03:40:00.334030Z","shell.execute_reply.started":"2024-06-05T03:40:00.329058Z","shell.execute_reply":"2024-06-05T03:40:00.333213Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model\nmodel.train(data=data_dir,\n            epochs=150,\n            batch=16,\n            imgsz=64,\n            device=0,\n            workers=12,\n            project='wafer_defects',\n            name='EXP00010',\n            seed=10,\n            deterministic=True,\n            val=True,\n            # save_json=True,\n            # save_conf=True,\n            dropout=0.15,   # default 0.0\n            mosaic=0.96,    # default 1.0\n            # flipud=0.0,     # default 0.0\n            # fliplr=0.5,     # default 0.5\n            # scale=0.5,      # default 0.5\n            # translate=0.1,  # default 0.1\n            degrees=50,     # default 0.0\n            # mixup=0.0,      # default 0.0\n            # copy_paste=0.0  # default 0.0\n            patience=50,\n            pretrained=False,\n            optimizer='SGD',\n            close_mosaic=0,\n            plots=True\n            )","metadata":{"execution":{"iopub.status.busy":"2024-06-05T03:40:00.335156Z","iopub.execute_input":"2024-06-05T03:40:00.335412Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.yaml, data=/kaggle/working/data, epochs=150, time=None, patience=50, batch=16, imgsz=64, save=True, save_period=-1, cache=False, device=0, workers=12, project=wafer_defects, name=EXP00010, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=10, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.15, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=50, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.96, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=wafer_defects/EXP00010\n\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/data/train... found 21288 images in 38 classes âœ… \n\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/data/val... found 5322 images in 38 classes âœ… \n\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/data/test... found 11405 images in 38 classes âœ… \n","output_type":"stream"},{"name":"stderr","text":"2024-06-05 03:40:01,962\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-06-05 03:40:02,805\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=1000 with nc=38\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    378918  ultralytics.nn.modules.head.Classify         [256, 38]                     \nYOLOv8n-cls summary: 99 layers, 1486966 parameters, 1486966 gradients, 3.4 GFLOPs\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir wafer_defects/EXP00010', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240605_034056-jafpvu0y</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/unimalaya/wafer_defects/runs/jafpvu0y' target=\"_blank\">EXP00010</a></strong> to <a href='https://wandb.ai/unimalaya/wafer_defects' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/unimalaya/wafer_defects' target=\"_blank\">https://wandb.ai/unimalaya/wafer_defects</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/unimalaya/wafer_defects/runs/jafpvu0y' target=\"_blank\">https://wandb.ai/unimalaya/wafer_defects/runs/jafpvu0y</a>"},"metadata":{}},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 75.5MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/data/train... 21288 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21288/21288 [00:06<00:00, 3201.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/data/train.cache\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/val... 5322 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5322/5322 [00:01<00:00, 3120.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/data/val.cache\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 64 train, 64 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mwafer_defects/EXP00010\u001b[0m\nStarting training for 150 epochs...\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/150     0.138G      3.653         16         64:   1%|â–         | 18/1331 [00:01<01:03, 20.79it/s]","output_type":"stream"},{"name":"stdout","text":"Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"      1/150     0.138G      3.663         16         64:   3%|â–Ž         | 36/1331 [00:02<00:52, 24.87it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 15.4MB/s]   64:   3%|â–Ž         | 36/1331 [00:02<00:52, 24.87it/s]\n      1/150     0.141G      3.078          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:48<00:00, 27.49it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 73.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.333      0.884\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/150     0.141G      1.982          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:43<00:00, 30.77it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 78.38it/s]","output_type":"stream"},{"name":"stdout","text":"                   all      0.633      0.977\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      3/150     0.141G      1.604          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:40<00:00, 32.54it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 75.33it/s]","output_type":"stream"},{"name":"stdout","text":"                   all      0.735      0.987\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      4/150     0.141G      1.417          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:40<00:00, 33.23it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 75.45it/s]","output_type":"stream"},{"name":"stdout","text":"                   all      0.834      0.996\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/150     0.141G      1.185          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:40<00:00, 32.97it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 79.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all      0.885      0.998\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      6/150     0.141G      1.063          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:40<00:00, 33.18it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 80.14it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       0.88      0.998\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/150     0.141G     0.9988          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:39<00:00, 33.77it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 70.20it/s]","output_type":"stream"},{"name":"stdout","text":"                   all      0.919          1\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      8/150     0.141G     0.9442          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:39<00:00, 33.45it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 79.38it/s]","output_type":"stream"},{"name":"stdout","text":"                   all      0.918      0.999\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      9/150     0.141G     0.9003         16         64:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 906/1331 [00:26<00:12, 35.42it/s]","output_type":"stream"}]},{"cell_type":"code","source":"# Deploy model that has been previously trained\nweights = \"/kaggle/working/wafer_defects/EXP00010/weights/best.pt\"\nmodel = YOLO(weights)  \n\n# Setting data directory\ndata_dir = Path(\"/kaggle/working/data\")\n\n# Evaluate the model on the test data split\nmodel.val(data=data_dir,split='test',save_json=True,plots=True)\n\n# Metric extraction\ncls_count = model.metrics.confusion_matrix.nc\ncls_names = model.names\nmatrix = model.metrics.confusion_matrix.matrix \n\ntp, fp = model.metrics.confusion_matrix.tp_fp() # true positive and false positive (total of true class incorrect)\nfn = np.array([(matrix[:,c:c+1].sum() - matrix[c,c]) for c in range(cls_count)]) # false negative, (total of predicted class incorrect)\n\n# Per-class metric calculation\nclass_metrics = dict()\nall_p, all_r, all_f1, all_acc = [], [], [], []\nfor c in range(cls_count):\n    recall = tp[c] / (tp[c] + fn[c])\n    precision = tp[c] / (tp[c] + fp[c])\n    accuracy = (tp[c] + 0) / (tp[c] + 0 + fp[c] + fn[c]) # zeros are True-Negatives, but there are none for this dataset\n    f1_score = (2 * precision * recall) / (precision + recall)\n    class_metrics[cls_names[c]] = np.array([precision, recall, f1_score, accuracy])\n    all_p.append(precision)\n    all_r.append(recall)\n    all_f1.append(f1_score)\n    all_acc.append(accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:34:43.992870Z","iopub.execute_input":"2024-06-05T05:34:43.993703Z","iopub.status.idle":"2024-06-05T05:34:54.851887Z","shell.execute_reply.started":"2024-06-05T05:34:43.993660Z","shell.execute_reply":"2024-06-05T05:34:54.850688Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\nYOLOv8n-cls summary (fused): 73 layers, 1483558 parameters, 0 gradients, 3.3 GFLOPs\n\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/data/train... found 21288 images in 38 classes âœ… \n\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/data/val... found 5322 images in 38 classes âœ… \n\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/data/test... found 11405 images in 38 classes âœ… \n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtest: \u001b[0mScanning /kaggle/working/data/test... 11405 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11405/11405 [00:00<?, ?it/s]\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 713/713 [00:06<00:00, 116.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.977          1\nSpeed: 0.0ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\nResults saved to \u001b[1mruns/classify/val2\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"}]},{"cell_type":"code","source":"print(all_acc)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:35:00.354249Z","iopub.execute_input":"2024-06-05T05:35:00.355208Z","iopub.status.idle":"2024-06-05T05:35:00.361082Z","shell.execute_reply.started":"2024-06-05T05:35:00.355171Z","shell.execute_reply":"2024-06-05T05:35:00.359866Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"[0.9508196721311475, 0.9409937888198758, 0.9572368421052632, 0.9593220338983051, 0.9411764705882353, 0.9348534201954397, 0.9625, 0.9324324324324325, 0.9131832797427653, 0.9581993569131833, 0.9554140127388535, 0.9761904761904762, 0.9662162162162162, 0.9838187702265372, 0.9240121580547113, 0.9716981132075472, 0.9785276073619632, 0.934375, 0.9595015576323987, 0.9329073482428115, 0.9473684210526315, 0.9379310344827586, 0.9607843137254902, 0.9658385093167702, 0.9552715654952076, 0.9305555555555556, 0.9665653495440729, 0.9614035087719298, 0.9290780141843972, 0.9619047619047619, 0.9675324675324676, 0.9785276073619632, 0.9415584415584416, 0.9781021897810219, 0.9074074074074074, 0.9968454258675079, 0.9748953974895398, 0.9649122807017544]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(np.mean(all_p))\nprint(np.mean(all_r))\nprint(np.mean(all_f1))\nprint(np.mean(all_acc))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:35:02.731255Z","iopub.execute_input":"2024-06-05T05:35:02.731638Z","iopub.status.idle":"2024-06-05T05:35:02.738382Z","shell.execute_reply.started":"2024-06-05T05:35:02.731611Z","shell.execute_reply":"2024-06-05T05:35:02.737133Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"0.9754835642857783\n0.9781071892611574\n0.9764593731113554\n0.954206863379785\n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving evaluation results\n\n# Define file paths\nmatrix_file = \"/kaggle/working/runs/classify/val2/confusion.csv\"\nmetrics_file = \"/kaggle/working/runs/classify/val2/metrics.yaml\"\nnames_file = \"/kaggle/working/runs/classify/val2/class_indices.yaml\"\ntp_fp_fn_file = \"/kaggle/working/runs/classify/val2/tp_fp_fn_counts.yaml\"\n\n# Save confusion matrix CSV file\nimport pandas as pd\n_ = pd.DataFrame(matrix).to_csv(matrix_file)\n\n# Save YAML files\nmetrics_export = {k: {'precision': float(v[0]), 'recall': float(v[1]), 'f1-score': float(v[2]), 'accuracy': float(v[3])} for k, v in class_metrics.items()}\nmetrics_export.update({'Average': {'precision': float(np.mean(all_p)), 'recall': float(np.mean(all_r)), 'f1-score': float(np.mean(all_f1)), 'accuracy': float(np.mean(all_acc))}})\nwith open(metrics_file, 'w') as met:\n    yaml.safe_dump(metrics_export, met)\n\nwith open(names_file, 'w') as nf:\n    yaml.safe_dump(cls_names, nf)\n\ntp_fp_fn_counts = {int(i): {'tp': int(tp[i]), 'fp': int(fp[i]), 'fn': int(fn[i])} for i in range(cls_count)}\nwith open(tp_fp_fn_file, 'w') as cnt_f:\n    yaml.safe_dump(tp_fp_fn_counts, cnt_f)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T05:35:21.233224Z","iopub.execute_input":"2024-06-05T05:35:21.233919Z","iopub.status.idle":"2024-06-05T05:35:21.281439Z","shell.execute_reply.started":"2024-06-05T05:35:21.233885Z","shell.execute_reply":"2024-06-05T05:35:21.280355Z"},"trusted":true},"execution_count":29,"outputs":[]}]}