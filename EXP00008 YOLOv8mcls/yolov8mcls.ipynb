{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1994091,"sourceType":"datasetVersion","datasetId":899128},{"sourceId":8202172,"sourceType":"datasetVersion","datasetId":4859203}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom pathlib import Path\nimport yaml\nimport cv2 as cv\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-04T14:30:05.161370Z","iopub.execute_input":"2024-06-04T14:30:05.161823Z","iopub.status.idle":"2024-06-04T14:30:05.167410Z","shell.execute_reply.started":"2024-06-04T14:30:05.161793Z","shell.execute_reply":"2024-06-04T14:30:05.166337Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def prev_im(image, string=\"\"):\n    \"\"\"\n    Display an image in a window with OpenCV.\n\n    Parameters:\n    ---\n    image : numpy.ndarray\n        The image to be displayed, expected to be in the format readable by OpenCV (usually uint8, with dimensions [height, width, channels]).\n    string : str, optional\n        The title of the window in which the image will be displayed. Default is an empty string.\n\n    Returns:\n    ---\n    None\n    \"\"\"\n    cv.imshow(string, image)  # Display the image in a window with the title provided in 'string'.\n    cv.waitKey(0)            # Wait indefinitely until a key is pressed.\n    cv.destroyAllWindows()   # Close all OpenCV windows.","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:30:05.169587Z","iopub.execute_input":"2024-06-04T14:30:05.170061Z","iopub.status.idle":"2024-06-04T14:30:05.182791Z","shell.execute_reply.started":"2024-06-04T14:30:05.170026Z","shell.execute_reply":"2024-06-04T14:30:05.181834Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Image Processing - Grayscale Conversion\ndef gen_gray_img(map_data: np.ndarray, debug=False):\n    \"\"\"\n    Generate a gray-scale image from wafer data.\n\n    Parameters:\n    ---\n    map_data : numpy.ndarray\n        Wafer data map with pixel values of (0, 1, 2); 0=non-wafer, 1=good wafer, 2=bad wafer.\n    debug : bool, optional\n        If True, performs checks and logs issues instead of raising exceptions.\n\n    Returns:\n    ---\n    numpy.ndarray\n        Gray-scale image with pixel values (0, 128, 255).\n    \"\"\"\n    expected_values = {0, 1, 2}\n    unique_values = np.unique(map_data)\n    \n    if not expected_values.issuperset(unique_values):\n        if debug:\n            print(f\"Unexpected values found in map_data: {unique_values}\")\n            return None\n        else:\n            raise ValueError(f\"Map values do not match expected values (0, 1, 2)\")\n\n    gray = np.copy(map_data)\n    gray[gray == 1] += 127\n    gray[gray == 2] += 253  # direct assignment to max value for clarity\n\n    return gray.astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:30:05.183945Z","iopub.execute_input":"2024-06-04T14:30:05.184235Z","iopub.status.idle":"2024-06-04T14:30:05.192718Z","shell.execute_reply.started":"2024-06-04T14:30:05.184206Z","shell.execute_reply":"2024-06-04T14:30:05.191881Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Image Processing - Colour Encoding\ndef gray_to_color(gray_map:np.ndarray,\n                  bad_clr:tuple=(255,255,0),\n                  good_clr:tuple=(25,102,255)):\n    \"\"\"\n    Usage\n    ---\n    Convert gray-scale image to color image using `good_clr` and `bad_clr` BGR colors\n\n    Parameters\n    ---\n    gray_map : ``numpy.ndarray``\n    bad_clr : ``tuple`` optional,\n        BGR color values to use for 'bad' pixels, `default=(255,255,0)` \"Pumpkin\"\n    good_clr : ``tuple`` optional,\n        BGR color values to use for 'good' pixels, `default=(25,102,255)` \"Aqua\"\n\n    Returns\n    ---\n    BGR color image of wafer map, using `good_clr` and `bad_clr` pixel values\n\n    \"\"\"\n    assert all([n in np.unique(gray_map) for n in [0,128,255]]), f\"Gray scale values do not match expected values (0, 128, 255)\"\n\n    color_map = cv.cvtColor(np.copy(gray_map),cv.COLOR_GRAY2BGR) # B, G, R\n    \n    for d in range(color_map.shape[-1]):\n            color_map[:,:,d][color_map[:,:,d] == 255] = bad_clr[d]\n            color_map[:,:,d][color_map[:,:,d] == 128] = good_clr[d]\n    \n    return color_map","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:30:05.195206Z","iopub.execute_input":"2024-06-04T14:30:05.195604Z","iopub.status.idle":"2024-06-04T14:30:05.205320Z","shell.execute_reply.started":"2024-06-04T14:30:05.195573Z","shell.execute_reply":"2024-06-04T14:30:05.204557Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Data Loading\nimport pandas as pd\ndata = np.load(\"/kaggle/input/mixedtype-wafer-defect-datasets/Wafer_Map_Datasets.npz\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:30:05.206428Z","iopub.execute_input":"2024-06-04T14:30:05.207028Z","iopub.status.idle":"2024-06-04T14:30:05.548686Z","shell.execute_reply.started":"2024-06-04T14:30:05.206997Z","shell.execute_reply":"2024-06-04T14:30:05.547842Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Seperate wafer map data and labels\nimgs = data['arr_0'] # shape (38015, 52, 52)\nlbls = data['arr_1'] # shape (38015, 8)\n\n# Get unique labels\nunique_lbls = np.unique(lbls,axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:30:05.549817Z","iopub.execute_input":"2024-06-04T14:30:05.550228Z","iopub.status.idle":"2024-06-04T14:30:08.637275Z","shell.execute_reply.started":"2024-06-04T14:30:05.550204Z","shell.execute_reply":"2024-06-04T14:30:08.636325Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Convert each label row to a tuple for it to be hashable\nlabel_tuples = [tuple(label) for label in lbls]\n\n# Use a dictionary to count occurrences of each unique label\nlabel_count = {}\nfor label in label_tuples:\n    if label in label_count:\n        label_count[label] += 1\n    else:\n        label_count[label] = 1\n\n# Display the counts\nfor label, count in label_count.items():\n    print(f\"Label {label}: {count} images\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:30:08.638504Z","iopub.execute_input":"2024-06-04T14:30:08.638810Z","iopub.status.idle":"2024-06-04T14:30:08.836047Z","shell.execute_reply.started":"2024-06-04T14:30:08.638786Z","shell.execute_reply":"2024-06-04T14:30:08.835166Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Label (1, 0, 1, 0, 0, 0, 1, 0): 2000 images\nLabel (1, 0, 1, 0, 0, 0, 0, 0): 1000 images\nLabel (1, 0, 0, 1, 0, 0, 1, 0): 1000 images\nLabel (1, 0, 0, 1, 0, 0, 0, 0): 1000 images\nLabel (1, 0, 1, 0, 1, 0, 1, 0): 1000 images\nLabel (1, 0, 1, 0, 1, 0, 0, 0): 1000 images\nLabel (1, 0, 0, 1, 1, 0, 1, 0): 1000 images\nLabel (1, 0, 0, 1, 1, 0, 0, 0): 1000 images\nLabel (1, 0, 0, 0, 1, 0, 1, 0): 1000 images\nLabel (1, 0, 0, 0, 1, 0, 0, 0): 1000 images\nLabel (1, 0, 0, 0, 0, 0, 1, 0): 1000 images\nLabel (1, 0, 0, 0, 0, 0, 0, 0): 1000 images\nLabel (0, 1, 1, 0, 0, 0, 1, 0): 1000 images\nLabel (0, 1, 1, 0, 0, 0, 0, 0): 1000 images\nLabel (0, 1, 0, 1, 0, 0, 1, 0): 1000 images\nLabel (0, 1, 0, 1, 0, 0, 0, 0): 1000 images\nLabel (0, 1, 1, 0, 1, 0, 1, 0): 1000 images\nLabel (0, 1, 1, 0, 1, 0, 0, 0): 1000 images\nLabel (0, 1, 0, 1, 1, 0, 1, 0): 1000 images\nLabel (0, 1, 0, 1, 1, 0, 0, 0): 1000 images\nLabel (0, 1, 0, 0, 1, 0, 1, 0): 1000 images\nLabel (0, 1, 0, 0, 1, 0, 0, 0): 1000 images\nLabel (0, 1, 0, 0, 0, 0, 1, 0): 1000 images\nLabel (0, 1, 0, 0, 0, 0, 0, 0): 1000 images\nLabel (0, 0, 1, 0, 0, 0, 0, 0): 1000 images\nLabel (0, 0, 0, 1, 0, 0, 0, 0): 1000 images\nLabel (0, 0, 1, 0, 1, 0, 1, 0): 1000 images\nLabel (0, 0, 1, 0, 1, 0, 0, 0): 1000 images\nLabel (0, 0, 0, 1, 1, 0, 1, 0): 1000 images\nLabel (0, 0, 0, 1, 1, 0, 0, 0): 1000 images\nLabel (0, 0, 0, 0, 1, 0, 1, 0): 1000 images\nLabel (0, 0, 0, 0, 1, 0, 0, 0): 1000 images\nLabel (0, 0, 0, 0, 0, 0, 0, 1): 866 images\nLabel (0, 0, 0, 0, 0, 0, 0, 0): 1000 images\nLabel (0, 0, 0, 0, 0, 1, 0, 0): 149 images\nLabel (0, 0, 1, 0, 0, 0, 1, 0): 1000 images\nLabel (0, 0, 0, 1, 0, 0, 1, 0): 1000 images\nLabel (0, 0, 0, 0, 0, 0, 1, 0): 1000 images\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load encoding file and create string labels\n# YAML file provides a structured way to map arrays of numeric labels to human-readable strings, which describe various types of wafer defects.\nencodes_path = \"/kaggle/input/encodings-yaml/encodings.yaml\"\nwith open(encodes_path, 'r') as enc:\n    encd = yaml.safe_load(enc)\n\nstr_lbls = [str(l) for l in lbls]","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:30:08.837370Z","iopub.execute_input":"2024-06-04T14:30:08.838016Z","iopub.status.idle":"2024-06-04T14:30:11.103457Z","shell.execute_reply.started":"2024-06-04T14:30:08.837980Z","shell.execute_reply":"2024-06-04T14:30:11.102661Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Show the number of unique pixel values in the uncleaned data\nunique_pixels = set()  # To store all unique pixel values across all images\nbad_wafers = []        # To store images that are considered bad based on pixel values\n\n# Analyze each wafer image\nfor img in imgs:\n    vals = np.unique(img).tolist()  # Get unique pixel values in the current image\n    unique_pixels.update(vals)      # Update the set of unique pixel values\n\n    # Check for unexpected pixel values\n    if len(vals) > 3:\n        bad_wafers.append(img)      # Append to bad wafers if unexpected values are found\n\n# Display the results\nprint(f\"Unique pixel values before cleaning: {unique_pixels}\")\nprint(f\"Number of bad wafers: {len(bad_wafers)}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:30:11.104767Z","iopub.execute_input":"2024-06-04T14:30:11.105113Z","iopub.status.idle":"2024-06-04T14:30:12.589597Z","shell.execute_reply.started":"2024-06-04T14:30:11.105086Z","shell.execute_reply":"2024-06-04T14:30:12.588607Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Unique pixel values before cleaning: {0, 1, 2, 3}\nNumber of bad wafers: 105\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fix imgs with more than 3 pixel values\n# should ONLY have 0,1,2 for values\n# see https://github.com/Junliangwangdhu/WaferMap/issues/2\nfor im in imgs:\n    val = np.unique(im)\n    if len(val) > 3:\n        im[im == 3] = 2","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:30:12.593193Z","iopub.execute_input":"2024-06-04T14:30:12.593533Z","iopub.status.idle":"2024-06-04T14:30:14.066665Z","shell.execute_reply.started":"2024-06-04T14:30:12.593509Z","shell.execute_reply":"2024-06-04T14:30:14.065661Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Train-Test split\n# y is generated by mapping the labels (lbls) to their corresponding encoded keys using a dictionary (encd).\nX, y = imgs, [list(encd.keys())[list(encd.values()).index(k.tolist())] for k in lbls] \n\n# Split data into test and temp sets\nX_train_temp, X_test, y_train_temp, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n\n# Further split the temp set into train and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_train_temp, y_train_temp, test_size=0.2, random_state=10)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:30:14.068113Z","iopub.execute_input":"2024-06-04T14:30:14.068975Z","iopub.status.idle":"2024-06-04T14:30:14.418386Z","shell.execute_reply.started":"2024-06-04T14:30:14.068941Z","shell.execute_reply":"2024-06-04T14:30:14.417624Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Review counts to analyze the distribution of labels across your training, validation, and test sets after the data split.\ntrain_lbl_counts = {k:v for k,v in zip(*np.unique(y_train,return_counts=True))}\nval_lbl_counts = {k:v for k,v in zip(*np.unique(y_val,return_counts=True))}\ntest_lbl_counts = {k:v for k,v in zip(*np.unique(y_test,return_counts=True))}","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:30:14.419474Z","iopub.execute_input":"2024-06-04T14:30:14.420067Z","iopub.status.idle":"2024-06-04T14:30:14.443399Z","shell.execute_reply.started":"2024-06-04T14:30:14.420041Z","shell.execute_reply":"2024-06-04T14:30:14.442621Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Define directory paths\ntrain_dir = '/kaggle/working/data/train'\nval_dir = '/kaggle/working/data/val'\ntest_dir = '/kaggle/working/data/test'\n\n# Create directories if they don't exist\nos.makedirs(train_dir, exist_ok=True)\nos.makedirs(val_dir, exist_ok=True)\nos.makedirs(test_dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:30:14.444509Z","iopub.execute_input":"2024-06-04T14:30:14.444787Z","iopub.status.idle":"2024-06-04T14:30:14.450686Z","shell.execute_reply.started":"2024-06-04T14:30:14.444765Z","shell.execute_reply":"2024-06-04T14:30:14.449394Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Train\n# Directory setup for each class, image processing, image resizing, saving the processed image\nfor ct, t in enumerate(X_train):\n    cls_dir = f\"{train_dir}/{y_train[ct]}\"\n    if not Path(cls_dir).exists():\n        _ = Path.mkdir(Path(cls_dir))\n    else:\n        pass\n    filename = f\"{cls_dir}/{ct}.png\"\n    color = gray_to_color(gen_gray_img(t))\n    stride_szd = cv.resize(np.copy(color),(64,64),interpolation=cv.INTER_CUBIC)\n    _ = cv.imwrite(filename,stride_szd)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:30:14.452179Z","iopub.execute_input":"2024-06-04T14:30:14.452466Z","iopub.status.idle":"2024-06-04T14:30:36.306752Z","shell.execute_reply.started":"2024-06-04T14:30:14.452441Z","shell.execute_reply":"2024-06-04T14:30:36.305992Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Validate\n# Directory setup for each class, image processing, image resizing, saving the processed image\nfor cval,val in enumerate(X_val):\n    cls_dir = f\"{val_dir}/{y_val[cval]}\"\n    if not Path(cls_dir).exists():\n        _ = Path.mkdir(Path(cls_dir))\n    else:\n        pass\n    filename = f\"{cls_dir}/{cval}.png\"\n    color = gray_to_color(gen_gray_img(val))\n    stride_szd = cv.resize(np.copy(color),(64,64),interpolation=cv.INTER_CUBIC)\n    _ = cv.imwrite(filename,stride_szd)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:30:36.307831Z","iopub.execute_input":"2024-06-04T14:30:36.308106Z","iopub.status.idle":"2024-06-04T14:30:41.681784Z","shell.execute_reply.started":"2024-06-04T14:30:36.308082Z","shell.execute_reply":"2024-06-04T14:30:41.680935Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Test\n# Directory setup for each class, image processing, image resizing, saving the processed image\nfor ctest,test in enumerate(X_test):\n    cls_dir = f\"{test_dir}/{y_test[ctest]}\"\n    if not Path(cls_dir).exists():\n        _ = Path.mkdir(Path(cls_dir))\n    else:\n        pass\n    filename = f\"{cls_dir}/{ctest}.png\"\n    color = gray_to_color(gen_gray_img(test))\n    stride_szd = cv.resize(np.copy(color),(64,64),interpolation=cv.INTER_CUBIC)\n    _ = cv.imwrite(filename,stride_szd)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:30:41.682901Z","iopub.execute_input":"2024-06-04T14:30:41.683252Z","iopub.status.idle":"2024-06-04T14:30:53.397272Z","shell.execute_reply.started":"2024-06-04T14:30:41.683222Z","shell.execute_reply":"2024-06-04T14:30:53.396462Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Generate color images for ALL wafer maps and save images to labeled directory\nfor k, v in encd.items():\n    # Define the directory path\n    directory_path = f'./wafers/{k}'\n    \n    # Check if the parent directory exists, if not create it\n    if not os.path.exists(directory_path):\n        os.makedirs(directory_path)\n    \n    # Get indices of matching groups\n    values, *_ = np.where(np.array(str_lbls) == str(v).replace(',', ''))\n\n    for idx in values:\n        # Create grayscale image\n        gray = gen_gray_img(imgs[idx])\n\n        # Convert to color\n        color = gray_to_color(gray)\n\n        # Resize for YOLO model, (64 x 64); multiple of model stride 32\n        stride_szd = cv.resize(np.copy(color), (64, 64), interpolation=cv.INTER_CUBIC)\n        _ = cv.imwrite(f'./wafers/{k}/' + str(idx) + '.png', stride_szd)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:30:53.398336Z","iopub.execute_input":"2024-06-04T14:30:53.398584Z","iopub.status.idle":"2024-06-04T14:31:30.584775Z","shell.execute_reply.started":"2024-06-04T14:30:53.398562Z","shell.execute_reply":"2024-06-04T14:31:30.583989Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"!pip install ultralytics\nfrom ultralytics import YOLO\nfrom pathlib import Path\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:31:30.585734Z","iopub.execute_input":"2024-06-04T14:31:30.585999Z","iopub.status.idle":"2024-06-04T14:31:48.549021Z","shell.execute_reply.started":"2024-06-04T14:31:30.585977Z","shell.execute_reply":"2024-06-04T14:31:48.548169Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.2.28-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.9.0.80)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.31.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.4)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.2)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.16.2)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.1)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=0.2.5 (from ultralytics)\n  Downloading ultralytics_thop-0.2.7-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.2.28-py3-none-any.whl (779 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-0.2.7-py3-none-any.whl (25 kB)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.2.28 ultralytics-thop-0.2.7\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load a model\nmodel = YOLO('yolov8m-cls.yaml')  \ndata_dir = Path(\"/kaggle/working/data\")\n\nmodel.to('cuda') if model.device.type == 'cpu' else None #moves the model to a CUDA-enabled GPU","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:31:48.550184Z","iopub.execute_input":"2024-06-04T14:31:48.550595Z","iopub.status.idle":"2024-06-04T14:31:49.195630Z","shell.execute_reply.started":"2024-06-04T14:31:48.550569Z","shell.execute_reply":"2024-06-04T14:31:49.194739Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"YOLOv8m-cls summary: 141 layers, 17053336 parameters, 17053336 gradients, 42.9 GFLOPs\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"YOLO(\n  (model): ClassificationModel(\n    (model): Sequential(\n      (0): Conv(\n        (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n      (1): Conv(\n        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n      (2): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (cv2): Conv(\n          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (m): ModuleList(\n          (0-1): 2 x Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act): SiLU()\n            )\n            (cv2): Conv(\n              (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act): SiLU()\n            )\n          )\n        )\n      )\n      (3): Conv(\n        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n      (4): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (cv2): Conv(\n          (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (m): ModuleList(\n          (0-3): 4 x Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act): SiLU()\n            )\n            (cv2): Conv(\n              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act): SiLU()\n            )\n          )\n        )\n      )\n      (5): Conv(\n        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n      (6): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (cv2): Conv(\n          (conv): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (m): ModuleList(\n          (0-3): 4 x Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act): SiLU()\n            )\n            (cv2): Conv(\n              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act): SiLU()\n            )\n          )\n        )\n      )\n      (7): Conv(\n        (conv): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act): SiLU()\n      )\n      (8): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (cv2): Conv(\n          (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (m): ModuleList(\n          (0-1): 2 x Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act): SiLU()\n            )\n            (cv2): Conv(\n              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (act): SiLU()\n            )\n          )\n        )\n      )\n      (9): Classify(\n        (conv): Conv(\n          (conv): Conv2d(768, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act): SiLU()\n        )\n        (pool): AdaptiveAvgPool2d(output_size=1)\n        (drop): Dropout(p=0.0, inplace=True)\n        (linear): Linear(in_features=1280, out_features=1000, bias=True)\n      )\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"print(os.getcwd())","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:31:49.196752Z","iopub.execute_input":"2024-06-04T14:31:49.197021Z","iopub.status.idle":"2024-06-04T14:31:49.202374Z","shell.execute_reply.started":"2024-06-04T14:31:49.196997Z","shell.execute_reply":"2024-06-04T14:31:49.201418Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model\nmodel.train(data=data_dir,\n            epochs=150,\n            batch=16,\n            imgsz=64,\n            device=0,\n            workers=12,\n            project='wafer_defects',\n            name='EXP00008',\n            seed=10,\n            deterministic=True,\n            val=True,\n            # save_json=True,\n            # save_conf=True,\n            dropout=0.15,   # default 0.0\n            mosaic=0.96,    # default 1.0\n            # flipud=0.0,     # default 0.0\n            # fliplr=0.5,     # default 0.5\n            # scale=0.5,      # default 0.5\n            # translate=0.1,  # default 0.1\n            degrees=50,     # default 0.0\n            # mixup=0.0,      # default 0.0\n            # copy_paste=0.0  # default 0.0\n            patience=50,\n            pretrained=False,\n            optimizer='SGD',\n            close_mosaic=0,\n            plots=True\n            )","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:31:49.203310Z","iopub.execute_input":"2024-06-04T14:31:49.203554Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8m-cls.yaml, data=/kaggle/working/data, epochs=150, time=None, patience=50, batch=16, imgsz=64, save=True, save_period=-1, cache=False, device=0, workers=12, project=wafer_defects, name=EXP00008, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=10, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.15, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=50, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.96, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=wafer_defects/EXP00008\n\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/data/train... found 21288 images in 38 classes âœ… \n\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/data/val... found 5322 images in 38 classes âœ… \n\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/data/test... found 11405 images in 38 classes âœ… \n","output_type":"stream"},{"name":"stderr","text":"2024-06-04 14:31:50,731\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-06-04 14:31:51,499\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=1000 with nc=38\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n  7                  -1  1   2655744  ultralytics.nn.modules.conv.Conv             [384, 768, 3, 2]              \n  8                  -1  2   7084032  ultralytics.nn.modules.block.C2f             [768, 768, 2, True]           \n  9                  -1  1   1034278  ultralytics.nn.modules.head.Classify         [768, 38]                     \nYOLOv8m-cls summary: 141 layers, 15821014 parameters, 15821014 gradients, 41.9 GFLOPs\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir wafer_defects/EXP00008', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240604_143307-fkct4ly8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/unimalaya/wafer_defects/runs/fkct4ly8' target=\"_blank\">EXP00008</a></strong> to <a href='https://wandb.ai/unimalaya/wafer_defects' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/unimalaya/wafer_defects' target=\"_blank\">https://wandb.ai/unimalaya/wafer_defects</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/unimalaya/wafer_defects/runs/fkct4ly8' target=\"_blank\">https://wandb.ai/unimalaya/wafer_defects/runs/fkct4ly8</a>"},"metadata":{}},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 22.5MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/data/train... 21288 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21288/21288 [00:06<00:00, 3460.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/data/train.cache\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/val... 5322 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5322/5322 [00:01<00:00, 3544.80it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/data/val.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 38 weight(decay=0.0), 39 weight(decay=0.0005), 39 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 64 train, 64 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mwafer_defects/EXP00008\u001b[0m\nStarting training for 150 epochs...\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/150     0.474G      3.678         16         64:   3%|â–Ž         | 42/1331 [00:02<00:57, 22.28it/s]","output_type":"stream"},{"name":"stdout","text":"Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"      1/150     0.474G       3.67         16         64:   7%|â–‹         | 87/1331 [00:04<00:56, 22.04it/s]\n      1/150     0.474G       3.67         16         64:   7%|â–‹         | 90/1331 [00:04<00:58, 21.15it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 4.34MB/s]   64:   7%|â–‹         | 90/1331 [00:04<00:58, 21.15it/s]\n      1/150     0.478G      3.207          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:57<00:00, 23.06it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 65.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.352      0.882\n\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/150     0.453G      1.938          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:51<00:00, 25.63it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 68.94it/s]","output_type":"stream"},{"name":"stdout","text":"                   all      0.585      0.971\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      3/150     0.455G      1.507          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:48<00:00, 27.16it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 60.46it/s]","output_type":"stream"},{"name":"stdout","text":"                   all      0.818      0.995\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      4/150     0.453G       1.33          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:48<00:00, 27.72it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 70.32it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       0.88      0.999\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/150     0.455G      1.102          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:48<00:00, 27.54it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 69.35it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       0.91      0.999\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      6/150     0.455G     0.9681          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:47<00:00, 27.80it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 69.01it/s]","output_type":"stream"},{"name":"stdout","text":"                   all      0.904      0.998\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/150     0.455G     0.9199          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:47<00:00, 27.81it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 70.28it/s]","output_type":"stream"},{"name":"stdout","text":"                   all      0.925          1\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      8/150     0.455G     0.8552          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:48<00:00, 27.46it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 70.90it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       0.93          1\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      9/150     0.457G     0.8037          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:48<00:00, 27.68it/s]\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:02<00:00, 70.06it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       0.94          1\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem       loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     10/150     0.455G     0.7986          8         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1331/1331 [00:48<00:00, 27.62it/s]\n               classes   top1_acc   top5_acc:   4%|â–         | 7/167 [00:00<00:02, 68.22it/s]","output_type":"stream"}]},{"cell_type":"code","source":"# Deploy model that has been previously trained\nweights = \"/kaggle/working/wafer_defects/EXP00008/weights/best.pt\"\nmodel = YOLO(weights)  \n\n# Setting data directory\ndata_dir = Path(\"/kaggle/working/data\")\n\n# Evaluate the model on the test data split\nmodel.val(data=data_dir,split='test',save_json=True,plots=True)\n\n# Metric extraction\ncls_count = model.metrics.confusion_matrix.nc\ncls_names = model.names\nmatrix = model.metrics.confusion_matrix.matrix \n\ntp, fp = model.metrics.confusion_matrix.tp_fp() # true positive and false positive (total of true class incorrect)\nfn = np.array([(matrix[:,c:c+1].sum() - matrix[c,c]) for c in range(cls_count)]) # false negative, (total of predicted class incorrect)\n\n# Per-class metric calculation\nclass_metrics = dict()\nall_p, all_r, all_f1, all_acc = [], [], [], []\nfor c in range(cls_count):\n    recall = tp[c] / (tp[c] + fn[c])\n    precision = tp[c] / (tp[c] + fp[c])\n    accuracy = (tp[c] + 0) / (tp[c] + 0 + fp[c] + fn[c]) # zeros are True-Negatives, but there are none for this dataset\n    f1_score = (2 * precision * recall) / (precision + recall)\n    class_metrics[cls_names[c]] = np.array([precision, recall, f1_score, accuracy])\n    all_p.append(precision)\n    all_r.append(recall)\n    all_f1.append(f1_score)\n    all_acc.append(accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T16:44:23.676201Z","iopub.execute_input":"2024-06-04T16:44:23.676539Z","iopub.status.idle":"2024-06-04T16:44:34.649968Z","shell.execute_reply.started":"2024-06-04T16:44:23.676512Z","shell.execute_reply":"2024-06-04T16:44:34.648825Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\nYOLOv8m-cls summary (fused): 103 layers, 15811334 parameters, 0 gradients, 41.7 GFLOPs\n\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/data/train... found 21288 images in 38 classes âœ… \n\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/data/val... found 5322 images in 38 classes âœ… \n\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/data/test... found 11405 images in 38 classes âœ… \n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtest: \u001b[0mScanning /kaggle/working/data/test... 11405 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11405/11405 [00:00<?, ?it/s]\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 713/713 [00:06<00:00, 109.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      0.982          1\nSpeed: 0.0ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\nResults saved to \u001b[1mruns/classify/val2\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"}]},{"cell_type":"code","source":"print(all_acc)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T16:44:48.554711Z","iopub.execute_input":"2024-06-04T16:44:48.555093Z","iopub.status.idle":"2024-06-04T16:44:48.560458Z","shell.execute_reply.started":"2024-06-04T16:44:48.555063Z","shell.execute_reply":"2024-06-04T16:44:48.559414Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"[0.9603960396039604, 0.9501557632398754, 0.9719934102141681, 0.9691780821917808, 0.9352750809061489, 0.9503311258278145, 0.9810126582278481, 0.9425675675675675, 0.9161290322580645, 0.9710610932475884, 0.9646302250803859, 0.9828767123287672, 0.9828767123287672, 0.9902912621359223, 0.9420731707317073, 0.9903846153846154, 0.9907692307692307, 0.949685534591195, 0.9716981132075472, 0.9424920127795527, 0.9537953795379538, 0.9515570934256056, 0.9672131147540983, 0.9749216300940439, 0.9647435897435898, 0.9479166666666666, 0.9695121951219512, 0.9575971731448764, 0.9397163120567376, 0.9680511182108626, 0.9706840390879479, 0.9755351681957186, 0.9607843137254902, 0.9962825278810409, 0.96, 1.0, 0.9916666666666667, 0.9649122807017544]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(np.mean(all_p))\nprint(np.mean(all_r))\nprint(np.mean(all_f1))\nprint(np.mean(all_acc))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T16:44:50.349058Z","iopub.execute_input":"2024-06-04T16:44:50.349485Z","iopub.status.idle":"2024-06-04T16:44:50.355450Z","shell.execute_reply.started":"2024-06-04T16:44:50.349450Z","shell.execute_reply":"2024-06-04T16:44:50.354510Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"0.9820653921649207\n0.9825311414263503\n0.9821082461803181\n0.9650201766220398\n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving evaluation results\n\n# Define file paths\nmatrix_file = \"/kaggle/working/runs/classify/val2/confusion.csv\"\nmetrics_file = \"/kaggle/working/runs/classify/val2/metrics.yaml\"\nnames_file = \"/kaggle/working/runs/classify/val2/class_indices.yaml\"\ntp_fp_fn_file = \"/kaggle/working/runs/classify/val2/tp_fp_fn_counts.yaml\"\n\n# Save confusion matrix CSV file\nimport pandas as pd\n_ = pd.DataFrame(matrix).to_csv(matrix_file)\n\n# Save YAML files\nmetrics_export = {k: {'precision': float(v[0]), 'recall': float(v[1]), 'f1-score': float(v[2]), 'accuracy': float(v[3])} for k, v in class_metrics.items()}\nmetrics_export.update({'Average': {'precision': float(np.mean(all_p)), 'recall': float(np.mean(all_r)), 'f1-score': float(np.mean(all_f1)), 'accuracy': float(np.mean(all_acc))}})\nwith open(metrics_file, 'w') as met:\n    yaml.safe_dump(metrics_export, met)\n\nwith open(names_file, 'w') as nf:\n    yaml.safe_dump(cls_names, nf)\n\ntp_fp_fn_counts = {int(i): {'tp': int(tp[i]), 'fp': int(fp[i]), 'fn': int(fn[i])} for i in range(cls_count)}\nwith open(tp_fp_fn_file, 'w') as cnt_f:\n    yaml.safe_dump(tp_fp_fn_counts, cnt_f)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T16:44:52.903029Z","iopub.execute_input":"2024-06-04T16:44:52.904031Z","iopub.status.idle":"2024-06-04T16:44:52.949857Z","shell.execute_reply.started":"2024-06-04T16:44:52.903986Z","shell.execute_reply":"2024-06-04T16:44:52.948949Z"},"trusted":true},"execution_count":33,"outputs":[]}]}